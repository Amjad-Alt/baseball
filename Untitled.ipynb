{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c4a3c068",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import glob\n",
    "import csv\n",
    "import sqlite3\n",
    "import glob\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58954e89",
   "metadata": {},
   "source": [
    "# Function that takes all CSV fiels and add them to one file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "58c4db7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# all the data set of Archive file in one database\n",
    "def do_directory(dirname, db):\n",
    "    for filename in glob.glob(os.path.join(dirname, '*.csv')):\n",
    "        do_file(filename, db)\n",
    "\n",
    "def do_file(filename, db):\n",
    "        with open(filename) as f:\n",
    "            with db:\n",
    "                data = csv.DictReader(f)\n",
    "                cols = data.fieldnames\n",
    "                table=os.path.splitext(os.path.basename(filename))[0]\n",
    "\n",
    "                sql = 'drop table if exists \"{}\"'.format(table)\n",
    "                db.execute(sql)\n",
    "\n",
    "                sql = 'create table \"{table}\" ( {cols} )'.format(\n",
    "                    table=table,\n",
    "                    cols=','.join('\"{}\"'.format(col) for col in cols))\n",
    "                db.execute(sql)\n",
    "\n",
    "                sql = 'insert into \"{table}\" values ( {vals} )'.format(\n",
    "                    table=table,\n",
    "                    vals=','.join('?' for col in cols))\n",
    "                db.executemany(sql, (list(map(row.get, cols)) for row in data))\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    conn = sqlite3.connect('foo2.db')\n",
    "    do_directory('.', conn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35157f51",
   "metadata": {},
   "source": [
    "# Make connection with SQL to organize the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4bc381a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = sqlite3.connect('archive (1)/foo.db')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a4b75379",
   "metadata": {},
   "outputs": [],
   "source": [
    "cursor = conn.cursor()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31d02f69",
   "metadata": {},
   "source": [
    "### Give me everything from Teams table and left juin them with the columns from Fitching table \n",
    "\n",
    "- deleted yearID , W, L, IPouts,SV,SHO,CG,ER,SF, from the Patch because when it is sum it is as the same as the team column\n",
    "- I choose to add both G,HR,BB, SO, ERA,HBP, R, H from both tables coz the sum of pitching is not as the team"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "aea9ed04",
   "metadata": {},
   "outputs": [],
   "source": [
    "db_df = pd.read_sql_query(\"\"\"\n",
    "SELECT  \n",
    "        t.*,\n",
    "        playerID, stint,p.G AS G_P, GS, \n",
    "        p.H AS H_P, p.HR AS HR_P, p.BB AS BB_P, p.SO AS SO_P, BAOpp, \n",
    "        p.ERA AS ERA_P, IBB, WP, p.HBP AS HBP_P, BK, BFP, GF,\n",
    "        p.R AS R_P, SH, GIDP\n",
    "        \n",
    "                            \n",
    "FROM   \n",
    "        Teams as t\n",
    "LEFT JOIN  Pitching as p\n",
    "ON  p.yearID = t.yearID AND\n",
    "    p.teamID = t.teamID \n",
    "  \n",
    "\"\"\", conn)\n",
    "db_df.to_csv('database.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19ca2ed6",
   "metadata": {},
   "source": [
    "### Give me everything from Fielding table and left juin them with the columns from Master table ,then another left join with Salary table\n",
    "- Deleted columns that are the same as database1 Stain coz it is as the same as database1\n",
    "- want only column weight, height, bats, throws from Master table \n",
    "- Want only salary from Salary table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "43390caf",
   "metadata": {},
   "outputs": [],
   "source": [
    "db_df = pd.read_sql_query(\"\"\"\n",
    "SELECT  \n",
    "        weight, height, bats, throws,\n",
    "        f.playerID, yearID, teamID, lgID, POS, G, GS, InnOuts, PO, A, E, DP, PB,\n",
    "        WP, SB, CS, ZR\n",
    "                              \n",
    "FROM   \n",
    "        Fielding AS f\n",
    "LEFT JOIN Master AS m\n",
    "ON  m.playerID = f.playerID \n",
    "  \n",
    "\"\"\", conn)\n",
    "\n",
    "db_df.to_csv('database2.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c0d43a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# all the data set in this direction which are database and database2 file in one database\n",
    "def do_directory(dirname, db):\n",
    "    for filename in glob.glob(os.path.join(dirname, '*.csv')):\n",
    "        do_file(filename, db)\n",
    "\n",
    "def do_file(filename, db):\n",
    "        with open(filename) as f:\n",
    "            with db:\n",
    "                data = csv.DictReader(f)\n",
    "                cols = data.fieldnames\n",
    "                table=os.path.splitext(os.path.basename(filename))[0]\n",
    "\n",
    "                sql = 'drop table if exists \"{}\"'.format(table)\n",
    "                db.execute(sql)\n",
    "\n",
    "                sql = 'create table \"{table}\" ( {cols} )'.format(\n",
    "                    table=table,\n",
    "                    cols=','.join('\"{}\"'.format(col) for col in cols))\n",
    "                db.execute(sql)\n",
    "\n",
    "                sql = 'insert into \"{table}\" values ( {vals} )'.format(\n",
    "                    table=table,\n",
    "                    vals=','.join('?' for col in cols))\n",
    "                db.executemany(sql, (list(map(row.get, cols)) for row in data))\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    conn = sqlite3.connect('foo2.db')\n",
    "    do_directory('.', conn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c204651",
   "metadata": {},
   "source": [
    "### Join database and database2 together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "a6dc4838",
   "metadata": {},
   "outputs": [],
   "source": [
    "db_df = pd.read_sql_query(\"\"\"\n",
    "SELECT  \n",
    "        database.*, POS,d.G AS G_F, d.GS AS GS_F, InnOuts, PO, A, d.E AS E_F,\n",
    "        d.DP AS DP_F, PB, d.WP AS WP_F, d.SB AS SB_F, d.CS AS AS_F, ZR\n",
    "\n",
    "                              \n",
    "FROM   \n",
    "        database \n",
    "LEFT JOIN database2 AS d\n",
    "ON  database.playerID = d.playerID AND database.yearID = d.yearID \n",
    "  \n",
    "\"\"\", conn)\n",
    "\n",
    "db_df.to_csv('database3.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3befac7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
